{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f4b0f85",
   "metadata": {},
   "source": [
    "# Day 3: Model Definition – Tabular Learner for Rossmann Data\n",
    "\n",
    "## 1. Objective\n",
    "- Load preprocessed tabular data\n",
    "- Recreate fastai `TabularDataLoaders`\n",
    "- Define tabular neural net model with embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1819ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload and preprocess from scratch\n",
    "from fastai.tabular.all import *\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "path = Path('../data/rossmann')\n",
    "df = pd.read_csv(path/'train.csv', low_memory=False)\n",
    "store_df = pd.read_csv(path/'store.csv')\n",
    "df = pd.merge(df, store_df, how='left', on='Store')\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "add_datepart(df, 'Date', drop=True)\n",
    "\n",
    "# Define features\n",
    "dep_var = 'Sales'\n",
    "cat_names = ['Store', 'DayOfWeek', 'StateHoliday', 'SchoolHoliday', 'StoreType', \n",
    "             'Assortment', 'Promo', 'Promo2', 'PromoInterval', 'Month', 'Day', 'Year', 'Week', 'Dayofweek']\n",
    "cont_names = ['Customers', 'Open', 'CompetitionDistance', 'CompetitionOpenSinceMonth',\n",
    "              'CompetitionOpenSinceYear', 'Promo2SinceWeek', 'Promo2SinceYear']\n",
    "procs = [Categorify, FillMissing, Normalize]\n",
    "splits = RandomSplitter(seed=42)(df)\n",
    "\n",
    "# Create loaders\n",
    "to = TabularPandas(df, procs, cat_names, cont_names, dep_var, splits=splits)\n",
    "dls = to.dataloaders(bs=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6916227d",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = tabular_learner(\n",
    "    dls,\n",
    "    layers=[200, 100],\n",
    "    metrics=rmse,\n",
    "    y_range=(0, df[dep_var].max())\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce91124",
   "metadata": {},
   "source": [
    "## 2. Model Definition\n",
    "\n",
    "We define a `tabular_learner` using fastai, which constructs a neural network designed for structured (tabular) data.\n",
    "\n",
    "**Key characteristics of this model:**\n",
    "\n",
    "- **Embedding Layers**: Each categorical variable is mapped to a learned embedding vector (e.g., `StoreType = a vector`), capturing similarities between categories.\n",
    "- **Normalized Continuous Inputs**: Continuous variables are scaled using statistics from the training set.\n",
    "- **Fully Connected Layers**: The embedding and continuous vectors are concatenated and passed through two hidden layers of 200 and 100 units.\n",
    "- **Dropout & ReLU**: Dropout is applied for regularization; ReLU is used as the activation function.\n",
    "- **Output Layer**: A single regression output (`Sales`), constrained using `y_range=(0, max_sales)` to ensure non-negative predictions.\n",
    "- **Metric**: Root Mean Squared Error (RMSE) is used to evaluate model performance.\n",
    "\n",
    "The learner object now contains all components (data, model, optimizer, loss function, metric) and is ready for training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc248ee",
   "metadata": {},
   "source": [
    "## 3. Model Summary and Embedding Sizes\n",
    "\n",
    "Before training, we inspect the model to:\n",
    "- Understand how fastai built the neural network\n",
    "- See which categorical variables are embedded and with what dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a249a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print model architecture\n",
    "learn.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7045081c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View embedding sizes for categorical variables\n",
    "learn.model.embeds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ef013e",
   "metadata": {},
   "source": [
    "## 4. Embedding Details\n",
    "\n",
    "Each categorical feature is assigned a learned embedding vector. The number of dimensions is automatically chosen by fastai based on cardinality of each column:\n",
    "\n",
    "| Feature         | Categories | Embedding Dim |\n",
    "|----------------|------------|----------------|\n",
    "| Store           | 1116       | 81             |\n",
    "| DayOfWeek       | 8          | 5              |\n",
    "| StateHoliday    | 5          | 4              |\n",
    "| SchoolHoliday   | 5          | 4              |\n",
    "| StoreType       | 3          | 3              |\n",
    "| Assortment      | 4          | 3              |\n",
    "| Promo           | 3          | 3              |\n",
    "| Promo2          | 3          | 3              |\n",
    "| PromoInterval   | 4          | 3              |\n",
    "| Month           | 13         | 7              |\n",
    "| Day             | 32         | 11             |\n",
    "| Year            | 4          | 3              |\n",
    "| Week            | 53         | 15             |\n",
    "| Dayofweek       | 8          | 5              |\n",
    "\n",
    "> Embedding dimensions follow fastai’s heuristic: `min(50, (n_cat+1)//2)`, where `n_cat` is the number of categories."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25d1ac7",
   "metadata": {},
   "source": [
    "## Why Does `Dayofweek` Have 8 Categories and 5 Embedding Dimensions?\n",
    "\n",
    "### 1. Category Count: Why 8?\n",
    "Although `Dayofweek` should only have 7 unique values (0 to 6 for Mon–Sun), fastai treats categorical variables with extra caution:\n",
    "- When using the `FillMissing` processor (which we did), fastai adds a special `\"NaN\"` category to each categorical feature by default.\n",
    "- This ensures that any missing values are treated as valid and learnable categories.\n",
    "\n",
    "**Result:**  \n",
    "7 real days + 1 \"NaN\" placeholder → **8 total categories**\n",
    "\n",
    "### 2. Embedding Dimension: Why 5?\n",
    "fastai uses a heuristic rule to decide how many dimensions each embedding vector should have: `embedding_dim = min(50, (n_cat + 1) // 2)`\n",
    "\n",
    "For `Dayofweek`:\n",
    "- `n_cat = 8`\n",
    "- `(8 + 1) // 2 = 4.5 → rounded to 5`\n",
    "\n",
    "**Result:**  \n",
    "Each day (including NaN) is mapped to a **5-dimensional vector**, which the model learns during training.\n",
    "\n",
    "These learned embeddings allow the model to capture subtleties like:\n",
    "- Sales patterns differing between weekdays and weekends\n",
    "- Saturdays and Sundays behaving similarly, but not identically\n",
    "- A missing value being handled explicitly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1757af10",
   "metadata": {},
   "source": [
    "## 6. Learning Rate Selection\n",
    "\n",
    "We used fastai’s `lr_find()` to explore how the training loss behaves across a range of learning rates.\n",
    "\n",
    "### Key Observations from the Plot:\n",
    "- **steep** (~1e-6): Too early — loss is still unstable and high\n",
    "- **slide** (~8e-7): Well before the loss begins to decline, not suitable\n",
    "- **valley** (~3e-3): Best choice — loss is falling rapidly and cleanly\n",
    "- **minimum** (~1e-2): Loss begins to flatten, but can be unstable or too slow\n",
    "\n",
    "### Chosen Learning Rate: `lr_max=3e-3`\n",
    "We selected the **valley** point (~`3e-3`) because it’s:\n",
    "- The start of the most stable downward trend in loss\n",
    "- Fast enough for good convergence\n",
    "- Avoids instability seen at lower or higher values\n",
    "\n",
    "This was passed into:\n",
    "```python\n",
    "learn.fit_one_cycle(5, lr_max=3e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6290e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find(suggest_funcs=(minimum, steep, valley, slide))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1080139",
   "metadata": {},
   "source": [
    "## 5. Model Training\n",
    "\n",
    "We now train the model using fastai’s high-level `.fit_one_cycle()` method. This schedules the learning rate for optimal convergence and monitors our metric (`rmse`) over each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8eb2c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model for 5 epochs using 1cycle learning rate policy\n",
    "learn.fit_one_cycle(5, lr_max=3e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aadb0398",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.export('../models/block7_tabular_rossmann.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8f99eb",
   "metadata": {},
   "source": [
    "## 7. Training Results and Loss Curve\n",
    "\n",
    "After training the model with `.fit_one_cycle()`, we plot the training and validation loss over time to evaluate performance and overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bba5ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training and validation losses over epochs\n",
    "learn.recorder.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460a9dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot loss\n",
    "learn.recorder.plot_loss()\n",
    "plt.title(\"Training and Validation Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "\n",
    "# Save manually\n",
    "plt.savefig('../plots/loss_curve_day3.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4c7c81",
   "metadata": {},
   "source": [
    "## 8. Loss Curve Analysis\n",
    "\n",
    "The plot above shows training and validation loss across batches and epochs.\n",
    "\n",
    "### Observations:\n",
    "- **Training Loss**: Decreases steadily with minor fluctuations, indicating the model is learning from the training data.\n",
    "- **Validation Loss**: Spikes intermittently and is significantly higher than training loss — especially noticeable in later stages of training.\n",
    "\n",
    "### Interpretation:\n",
    "- The model fits the training data well but struggles to generalize to the validation set.\n",
    "- The large gap between training and validation loss suggests **potential overfitting** or **data leakage issues** (e.g., validation set having unseen stores or promo patterns).\n",
    "- It may also indicate:\n",
    "  - Need for more regularization (e.g., higher dropout)\n",
    "  - An imbalanced or noisy target variable (`Sales`)\n",
    "  - Benefits from alternative validation strategies (e.g., time-based split)\n",
    "\n",
    "### Next Steps:\n",
    "- Consider increasing dropout or simplifying the model (fewer layers or neurons)\n",
    "- Review input features for data leakage\n",
    "- Experiment with more robust validation schemes (e.g., store-based splits)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai-tabular",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
