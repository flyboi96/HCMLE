{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b10a9e2",
   "metadata": {},
   "source": [
    "# Day 2: Data Preprocessing for Tabular Model (Rossmann)\n",
    "\n",
    "## 1. Objective\n",
    "- Load and inspect Rossmann dataset.\n",
    "- Merge datasets and handle missing values.\n",
    "- Identify categorical and continuous features.\n",
    "\n",
    "## 2. Key Steps\n",
    "- Load `train.csv` and `store.csv`\n",
    "- Merge them on `Store`\n",
    "- Inspect nulls, data types, and structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ffa146b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required packages\n",
    "from fastai.tabular.all import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# Set data path\n",
    "path = Path('../data/rossmann')\n",
    "assert path.exists(), \"Dataset path not found.\"\n",
    "\n",
    "# Load CSVs\n",
    "train_df = pd.read_csv(path/'train.csv', low_memory=False)\n",
    "store_df = pd.read_csv(path/'store.csv')\n",
    "\n",
    "print(\"Files loaded\")\n",
    "train_df.shape, store_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fc6d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge train with store metadata on 'Store'\n",
    "df = pd.merge(train_df, store_df, how='left', on='Store')\n",
    "\n",
    "# Peek at combined data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11081fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf15ddd",
   "metadata": {},
   "source": [
    "## 3. Results\n",
    "- Combined dataset has 1017209 rows and 18 columns.\n",
    "- Next: clean date column, identify missing values, and define variable types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb5b120",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{'Column':<20} {'Type':<15} {'Example'}\")\n",
    "print(\"-\" * 60)\n",
    "for col in df.columns:\n",
    "    dtype = df[col].dtype\n",
    "    example = df[col].dropna().iloc[0] if df[col].notna().any() else \"NaN\"\n",
    "    print(f\"{col:<20} {str(dtype):<15} {str(example)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e67a6b",
   "metadata": {},
   "source": [
    "## 4. Preprocessing\n",
    "We now convert the `Date` column to datetime, extract date features, and handle missing values.\n",
    "We'll also define which columns are categorical vs. continuous for use in fastai."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13eb7a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Date column\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "# Extract date features (fastai-style)\n",
    "add_datepart(df, 'Date', drop=True)\n",
    "\n",
    "# Look at missing values\n",
    "df.isna().sum()[df.isna().sum() > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662974e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define categorical and continuous variables\n",
    "dep_var = 'Sales'\n",
    "\n",
    "cat_names = ['Store', 'DayOfWeek', 'StateHoliday', 'SchoolHoliday', 'StoreType', \n",
    "             'Assortment', 'Promo', 'Promo2', 'PromoInterval', 'Month', 'Day', 'Year', 'Week', 'Dayofweek']\n",
    "\n",
    "cont_names = ['Customers', 'Open', 'CompetitionDistance', 'CompetitionOpenSinceMonth',\n",
    "              'CompetitionOpenSinceYear', 'Promo2SinceWeek', 'Promo2SinceYear']\n",
    "\n",
    "procs = [Categorify, FillMissing, Normalize]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a0e903",
   "metadata": {},
   "source": [
    "## 5. Summary\n",
    "- Date features extracted\n",
    "- Missing values handled (with fastai 'FillMissing')\n",
    "- Feature types split into categorical and continuous"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caab1fe6",
   "metadata": {},
   "source": [
    "## 6. Create TabularDataLoaders\n",
    "We'll use fastai's `TabularDataLoaders` to:\n",
    "- Apply preprocessing (categorify, fillmissing, normalize)\n",
    "- Build training/validation splits\n",
    "- Preview batches before model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b57aaf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# Random train/valid split\n",
    "splits = RandomSplitter(seed=42)(df)\n",
    "\n",
    "# Create DataLoaders\n",
    "dls = TabularDataLoaders.from_df(\n",
    "    df, \n",
    "    procs=procs,\n",
    "    cat_names=cat_names,\n",
    "    cont_names=cont_names,\n",
    "    y_names=dep_var,\n",
    "    splits=splits,\n",
    "    bs=64\n",
    ")\n",
    "\n",
    "dls.show_batch(max_n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2901dd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save a small sample (optional, for reference/debugging)\n",
    "df.head(100).to_csv('../data/rossmann/rossmann_sample.csv', index=False)\n",
    "print(\"Sample saved to data/rossmann/rossmann_sample.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bfe77fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best practice: save full TabularPandas (optional upgrade)\n",
    "to = TabularPandas(\n",
    "    df,\n",
    "    procs=procs,\n",
    "    cat_names=cat_names,\n",
    "    cont_names=cont_names,\n",
    "    y_names=dep_var,\n",
    "    splits=splits\n",
    ")\n",
    "\n",
    "import pickle\n",
    "\n",
    "with open('../data/rossmann_tabular.pkl', 'wb') as f:\n",
    "    pickle.dump(to, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72a3c54",
   "metadata": {},
   "source": [
    "## 7. Results\n",
    "\n",
    "- Loaded and merged `train.csv` and `store.csv` on `Store`\n",
    "- Parsed `Date` column and extracted date-based features (`Year`, `Month`, `Week`, etc.)\n",
    "- Handled missing values using fastai's `FillMissing` processor\n",
    "- Defined `cat_names` and `cont_names` for model inputs\n",
    "- Created `TabularDataLoaders` with randomized training/validation split\n",
    "- Previewed a clean batch with categorical encoding and normalization applied\n",
    "- Saved a snapshot of the processed data as `rossmann_sample.csv`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c46ce39",
   "metadata": {},
   "source": [
    "## 8. Summary\n",
    "\n",
    "- Preprocessing with fastai’s `TabularDataLoaders` allowed for seamless handling of categorical, continuous, and missing values\n",
    "- `add_datepart()` extracted useful temporal features from `Date` for tabular learning\n",
    "- Fastai’s `FillMissing` created companion `_na` columns, preserving interpretability\n",
    "- Defined structured lists of categorical and continuous variables for use in model training\n",
    "- Dataset is now fully processed and ready for deep learning — next step: build and train the model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai-tabular",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
