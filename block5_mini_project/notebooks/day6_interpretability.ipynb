{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "966cf698",
   "metadata": {},
   "source": [
    "# Day 6: Model Interpretability & Trust\n",
    "\n",
    "## 1. Objective\n",
    "\n",
    "Interpret the behavior of the models in a transparent and user-friendly way. Explain why key features influence predictions and assess whether the models are trustworthy enough for real-world use.\n",
    "\n",
    "## 2. Key Steps\n",
    "\n",
    "### Reload Final Models and Test Data\n",
    "- Reload the final **Logistic Regression** and **Random Forest** models.\n",
    "- Restore the cleaned dataset with proper categorical data types.\n",
    "- Reapply the same **train-test split** and **VIF-based feature pruning** (for logistic regression).\n",
    "- Standardize reduced features using the saved scaler to ensure model compatibility.\n",
    "- Confirm predictions align with original class orientation (\"Gallstones\", \"No Gallstones\").\n",
    "\n",
    "### Compute Feature Importances\n",
    "- Extract **logistic regression coefficients** to assess global, interpretable influence.\n",
    "- For the random forest:\n",
    "  - Compute **Mean Decrease in Impurity (MDI)** from `.feature_importances_`.\n",
    "  - Calculate **Permutation Importance** to assess feature sensitivity.\n",
    "  - Apply **SHAP values** to understand how individual features contribute to each prediction.\n",
    "\n",
    "### Visualize Top Contributing Features\n",
    "- Create a **bar plot** of the top 5 logistic regression coefficients with clear direction labels.\n",
    "- Combine MDI, permutation, and SHAP values into a **consolidated bar plot** for Random Forest.\n",
    "- Apply visual design principles from *Storytelling with Data*:\n",
    "  - Remove clutter.\n",
    "  - Use aligned axes and color to emphasize meaning.\n",
    "  - Add labels and titles that enhance clarity.\n",
    "\n",
    "### Interpret Features in Context\n",
    "- For each top predictor (e.g., `crp_mg_l`, `vitamin_d_ng_ml`, `alt_u_l`):\n",
    "  - Describe what the feature means clinically.\n",
    "  - Justify why it influences gallstone prediction.\n",
    "  - Explain if the direction of effect is **clinically plausible**.\n",
    "\n",
    "### Reflect on Interpretability and Transparency\n",
    "- Evaluate whether the **Logistic Regression model** provides **sufficient transparency** for use by clinicians or analysts.\n",
    "- Consider:\n",
    "  - Are the most influential features understandable to the end user?\n",
    "  - Would the model’s logic be **trusted and adopted** in a clinical decision-support tool?\n",
    "  - Are there **trade-offs** between accuracy and explainability?\n",
    "- Reflect on whether the **Random Forest** interpretability tools (SHAP, permutation) complement or challenge the linear model’s transparency.\n",
    "\n",
    "### Apply Visualization Principles\n",
    "- Summarize the 3 takeaways from *Storytelling with Data – Chapter 4: “Focus Your Audience’s Attention”*\n",
    "- Apply to today’s plots (e.g., clear color use, top-left-aligned annotations, minimal legend clutter).\n",
    "\n",
    "## 3. Results\n",
    "\n",
    "- Successfully reloaded both models and test data using consistent preprocessing pipelines.\n",
    "- Extracted and visualized top logistic regression coefficients, confirming that `crp_mg_l`, `hyperlipidemia`, and `diabetes` were strong positive predictors of gallstones, while `vitamin_d_ng_ml` and `ast_u_l` were negative predictors.\n",
    "- Used Random Forest interpretability techniques (MDI, permutation importance, SHAP) to validate and complement findings from the linear model.\n",
    "- Created professional-quality plots with minimal clutter and meaningful annotations, applying design principles from *Storytelling with Data*.\n",
    "- Determined that both models align with clinical reasoning, with Logistic Regression offering superior transparency and Random Forest providing more flexible modeling supported by interpretability layers.\n",
    "\n",
    "## 4. Summary\n",
    "\n",
    "Day 6 focused on **interpreting and trusting model behavior**, especially within a healthcare context. Through coefficient analysis and tree-based feature explanations, we demonstrated that both models make medically plausible decisions. Logistic Regression’s direct coefficients promote confidence in clinical settings, while SHAP and permutation importance make Random Forest’s black-box predictions more understandable. This dual approach supports model transparency, user trust, and the responsible application of machine learning in real-world medical decision support."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "369ef6a7",
   "metadata": {},
   "source": [
    "## Reload Final Models and Test Data\n",
    "\n",
    "To ensure reliable interpretation and comparison of model behavior, we reload all key components from the evaluation phase on Day 5:\n",
    "\n",
    "- The **Logistic Regression model**, which achieved the best test set performance, is reloaded from disk.\n",
    "- We also reload the **Random Forest model** for complementary tree-based interpretability (e.g., SHAP, permutation importance).\n",
    "- The same **cleaned dataset** is used, with categorical types restored to match the original feature encoding used during training.\n",
    "- **VIF-pruned features** are reapplied for Logistic Regression, and the test inputs are re-standardized using the saved `StandardScaler`.\n",
    "- For Random Forest, we use the full, non-reduced feature set (`X_test`) consistent with its training configuration.\n",
    "\n",
    "This controlled setup ensures **model explanations and diagnostics reflect the original decision space**, and all comparisons are based on **identical test conditions**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0980f7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load cleaned dataset\n",
    "df = pd.read_csv(\"../data/cleaned.csv\")\n",
    "\n",
    "# Restore categorical types\n",
    "categorical_cols = [\n",
    "    # Original binary or ordinal clinical features\n",
    "    \"gender\",\n",
    "    \"comorbidity\",\n",
    "    \"cad\",\n",
    "    \"hypothyroidism\",\n",
    "    \"hyperlipidemia\",\n",
    "    \"diabetes\",\n",
    "    \"hepatic_fat\",\n",
    "    \"has_gallstones\",\n",
    "\n",
    "    # Outlier flags (created during data cleaning)\n",
    "    \"glucose_outlier_flag\",\n",
    "    \"obesity_outlier_flag\",\n",
    "    \"muscle_mass_outlier_flag\",\n",
    "    \"gfr_outlier_flag\",\n",
    "    \"tbw_outlier_flag\",\n",
    "    \"icw_outlier_flag\",\n",
    "    \"vfr_outlier_flag\",\n",
    "    \"ldl_outlier_flag\",\n",
    "    \"hdl_outlier_flag\",\n",
    "    \"triglyceride_outlier_flag\",\n",
    "    \"alt_outlier_flag\",\n",
    "    \"crp_outlier_flag\"\n",
    "]\n",
    "for col in categorical_cols:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].astype(\"category\")\n",
    "\n",
    "# Define target and features\n",
    "target = \"has_gallstones\"\n",
    "y = df[target].replace({1: \"Gallstones\", 0: \"No Gallstones\"})  # Keep 0 and 1 for models\n",
    "X = df.drop(columns=[target])\n",
    "\n",
    "# Train-test split (same seed for consistency)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Reload dropped features list used for logistic regression VIF reduction\n",
    "features_dropped = ['height_cm', 'weight_kg', 'ecf_tbw_ratio_index', 'muscle_mass_kg',\n",
    "    'lean_mass_percent', 'bmi', 'ecw_kg', 'tbw_kg', 'icw_kg', 'fat_mass_kg', 'visceral_muscle_mass_kg',\n",
    "    'cholesterol_total_mg_dl', 'hemoglobin_g_dl', 'bone_mass_kg', 'protein_percent', 'visceral_fat_area_cm2',\n",
    "    'fat_ratio_percent', 'age', 'gfr_ml_min', 'creatinine_mg_dl', 'ldl_mg_dl', 'vfr_score', 'alp_u_l']\n",
    "\n",
    "# Recreate VIF-reduced test set\n",
    "X_reduced = X.drop(columns=features_dropped)\n",
    "X_train_reduced = X_train.drop(columns=features_dropped)\n",
    "X_test_reduced = X_test.drop(columns=features_dropped)\n",
    "\n",
    "# Load models and scaler\n",
    "logreg = joblib.load(\"../models/logistic_regression_model.joblib\")\n",
    "rf = joblib.load(\"../models/random_forest_model.joblib\")\n",
    "logreg_scaler = joblib.load(\"../models/logreg_scaler.joblib\")\n",
    "\n",
    "# VIF-reduced test set for logistic regression\n",
    "X_scaled = logreg_scaler.transform(X_reduced)\n",
    "X_train_scaled = logreg_scaler.transform(X_train_reduced)\n",
    "X_test_scaled = logreg_scaler.transform(X_test_reduced)\n",
    "\n",
    "# Logistic Regression\n",
    "logreg_preds = logreg.predict(X_test_scaled)  # returns 0 or 1\n",
    "logreg_probs = logreg.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Random Forest\n",
    "rf_preds = rf.predict(X_test)                # returns 0 or 1\n",
    "rf_probs = rf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"Models, scaler, and predictions loaded successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89a837b",
   "metadata": {},
   "source": [
    "## Compute Feature Importances – Logistic Regression\n",
    "\n",
    "We now interpret the logistic regression model by extracting the **learned coefficients**. In a linear model, these coefficients directly represent the relationship between input features and the log-odds of the positive class (\"Gallstones\").\n",
    "\n",
    "- **Positive coefficients**: Higher values increase the predicted risk of gallstones.\n",
    "- **Negative coefficients**: Higher values decrease the predicted risk.\n",
    "- The **magnitude** of each coefficient indicates its influence on the decision boundary.\n",
    "\n",
    "This provides a transparent, global view of what the model has learned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca614abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Get feature names in same order used by model\n",
    "feature_names = X_test_reduced.columns\n",
    "\n",
    "# Extract coefficients\n",
    "coefs = -logreg.coef_[0]\n",
    "\n",
    "# Create DataFrame for display\n",
    "importance_df = pd.DataFrame({\n",
    "    \"Feature\": feature_names,\n",
    "    \"Coefficient\": coefs\n",
    "})\n",
    "importance_df[\"Abs_Coefficient\"] = importance_df[\"Coefficient\"].abs()\n",
    "importance_df[\"Impact\"] = np.where(importance_df[\"Coefficient\"] > 0, \"↑ Gallstone Risk\", \"↓ Gallstone Risk\")\n",
    "\n",
    "# Sort by absolute magnitude\n",
    "importance_df = importance_df.sort_values(\"Abs_Coefficient\", ascending=False)\n",
    "\n",
    "# Plot top 5\n",
    "top_n = 5\n",
    "plt.figure(figsize=(7, 5))\n",
    "sns.barplot(data=importance_df.head(top_n), x=\"Coefficient\", y=\"Feature\", hue=\"Impact\", dodge=False)\n",
    "plt.title(\"Top Logistic Regression Coefficients\")\n",
    "plt.axvline(0, linestyle=\"--\", color=\"gray\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../plots/logreg_feature_importance.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd503dfb",
   "metadata": {},
   "source": [
    "## Interpreting Logistic Regression Coefficients\n",
    "\n",
    "This plot displays the top logistic regression coefficients used to predict gallstone risk. After correcting for class orientation, these coefficients indicate how each feature impacts the odds of a patient being classified as having gallstones.\n",
    "\n",
    "### Key Insights:\n",
    "\n",
    "- **↑ Gallstone Risk**:\n",
    "  - `crp_mg_l` (C-reactive protein) is the strongest positive predictor of gallstones, reinforcing its role as a marker of inflammation and acute gallbladder pathology.\n",
    "  - `hyperlipidemia` and `diabetes` also appear as significant contributors, aligning with known metabolic risk profiles for gallstone development.\n",
    "\n",
    "- **↓ Gallstone Risk**:\n",
    "  - `vitamin_d_ng_ml` and `ast_u_l` both show negative coefficients, suggesting protective associations. Low AST may indicate preserved liver health, while higher vitamin D levels are associated with reduced gallstone risk.\n",
    "\n",
    "### Clinical Interpretability:\n",
    "\n",
    "- The direction (positive or negative) of each coefficient clarifies whether the feature increases or decreases predicted risk.\n",
    "- The bar length reflects the **relative strength** of each predictor.\n",
    "- This model structure allows **transparent reasoning** and supports clinical decisions rooted in traceable logic.\n",
    "\n",
    "This coefficient-based explanation enhances user trust by clearly connecting input features to outcomes and aligns with evidence-based risk markers observed in hepatobiliary research."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51902aa",
   "metadata": {},
   "source": [
    "## Tree-Based Feature Importance Techniques\n",
    "\n",
    "To interpret the Random Forest model beyond raw accuracy, we explore multiple approaches to feature importance:\n",
    "\n",
    "- **Mean Decrease in Impurity (MDI)**: Built-in `.feature_importances_` attribute from scikit-learn, based on total reduction in Gini impurity.\n",
    "- **Permutation Importance**: Measures the drop in model performance when a single feature is randomly shuffled.\n",
    "- **SHAP (SHapley Additive exPlanations)**: Provides local and global interpretability by attributing prediction contributions to each feature, rooted in cooperative game theory.\n",
    "\n",
    "Together, these methods provide a robust understanding of how the model is making decisions, from high-level feature ranking to detailed patient-level rationale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a6eb91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.inspection import permutation_importance\n",
    "import shap\n",
    "\n",
    "# Create a numeric version of X_test_rf for SHAP\n",
    "X_test_encoded = X_test.copy()\n",
    "\n",
    "for col in X_test_encoded.select_dtypes(include=\"category\").columns:\n",
    "    X_test_encoded[col] = X_test_encoded[col].cat.codes\n",
    "\n",
    "# ----------------------------\n",
    "# 1. Mean Decrease in Impurity\n",
    "# ----------------------------\n",
    "mdi_importance = pd.DataFrame({\n",
    "    \"Feature\": X_test.columns,\n",
    "    \"Importance\": rf.feature_importances_,\n",
    "    \"Method\": \"MDI\"\n",
    "})\n",
    "\n",
    "# ----------------------------\n",
    "# 2. Permutation Importance\n",
    "# ----------------------------\n",
    "perm = permutation_importance(rf, X_test, y_test, n_repeats=10, random_state=42)\n",
    "perm_importance = pd.DataFrame({\n",
    "    \"Feature\": X_test.columns,\n",
    "    \"Importance\": perm.importances_mean,\n",
    "    \"Method\": \"Permutation\"\n",
    "})\n",
    "\n",
    "# ----------------------------\n",
    "# 3. SHAP Values\n",
    "# ----------------------------\n",
    "# Get SHAP values (multi-class format: [n_samples, n_features, n_classes])\n",
    "shap_values = explainer(X_test_encoded)\n",
    "\n",
    "# Select class 0 = \"Gallstones\"\n",
    "shap_class_index = list(rf.classes_).index(\"Gallstones\")\n",
    "shap_values_class = shap_values[..., shap_class_index]\n",
    "\n",
    "# Confirm shape now matches\n",
    "assert shap_values_class.shape == X_test_encoded.shape\n",
    "\n",
    "# Compute mean absolute SHAP value per feature\n",
    "shap_importance = pd.DataFrame({\n",
    "    \"Feature\": X_test_encoded.columns,\n",
    "    \"Importance\": np.abs(shap_values_class.values).mean(axis=0),\n",
    "    \"Method\": \"SHAP\"\n",
    "}).sort_values(\"Importance\", ascending=False)\n",
    "\n",
    "# Combine all results\n",
    "all_importances = pd.concat([mdi_importance, perm_importance, shap_importance], ignore_index=True)\n",
    "\n",
    "# Sort within each method\n",
    "top_importances = (\n",
    "    all_importances\n",
    "    .sort_values(\"Importance\", ascending=False)\n",
    "    .groupby(\"Method\", group_keys=False)\n",
    "    .head(5)  # Keep Method in result\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data=top_importances, x=\"Importance\", y=\"Feature\", hue=\"Method\")\n",
    "plt.title(\"Top 5 Features by Importance (Random Forest)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../plots/rf_feature_importances_combined.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d893292d",
   "metadata": {},
   "source": [
    "## Feature Importance Analysis – Random Forest\n",
    "\n",
    "We computed and visualized the top 5 features contributing to gallstone prediction using three complementary techniques:\n",
    "\n",
    "- **MDI (Mean Decrease in Impurity)** – Captures how much each feature reduces impurity across tree splits.\n",
    "- **Permutation Importance** – Measures drop in model performance when each feature is randomly shuffled.\n",
    "- **SHAP (SHapley Additive exPlanations)** – Provides additive, model-aware attributions for each prediction.\n",
    "\n",
    "### Key Insights\n",
    "\n",
    "- **CRP (C-Reactive Protein)** is the top feature across all three methods, supporting its known clinical relevance as an inflammation marker in biliary conditions.\n",
    "- **Vitamin D** is moderately important across SHAP and MDI, consistent with its proposed role in gallbladder and metabolic health.\n",
    "- **AST**, **ECF/TBW ratio**, and **fat ratio percent** rank highly in at least two methods, reinforcing their physiological linkage to gallstone risk.\n",
    "- Permutation importance yielded more conservative values, suggesting these features hold generalizable predictive power.\n",
    "\n",
    "### Interpretation\n",
    "\n",
    "- MDI can be biased toward correlated features or those with many unique values, but still signals useful global patterns.\n",
    "- Permutation tests performance robustness under input noise.\n",
    "- SHAP provides granular, instance-level explanations of prediction logic.\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "The convergence across methods—especially highlighting CRP and vitamin D—supports both the **statistical validity** and **clinical credibility** of the model. These insights improve trust in the Random Forest model’s reasoning and support its use in decision support systems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1c9591",
   "metadata": {},
   "source": [
    "## Reflecting on Interpretability and Transparency\n",
    "\n",
    "The **Logistic Regression model** offers strong transparency and traceability—its coefficients directly reflect how each feature influences the predicted risk of gallstones. Top predictors like `crp_mg_l` (inflammation marker), `vitamin_d_ng_ml`, and `hyperlipidemia` are both **clinically relevant** and **intuitively understandable** to a healthcare professional. This supports its suitability for use in clinical decision-support tools, where interpretability is critical.\n",
    "\n",
    "While **Random Forest** provided slightly higher cross-validated AUC, its internal decision process is more opaque. However, supplementing it with **SHAP** and **Permutation Importance** mitigates this limitation by offering instance-level and model-level explanations. These tools enhance trust without fully replacing the simplicity of the linear model.\n",
    "\n",
    "**Conclusion**: Logistic Regression strikes a strong balance between performance and interpretability. Its explainability is sufficient for frontline clinical users, and tree-based models—with additional interpretability layers—offer complementary perspectives for more complex decision environments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef39303",
   "metadata": {},
   "source": [
    "## Storytelling with Data – Chapter 4 Takeaways: *Focus Your Audience’s Attention*\n",
    "\n",
    "1. **Guide the Eye Intentionally**  \n",
    "   Use visual hierarchy, contrast, and layout to steer the viewer toward what matters most. Techniques like bolding, size, or positioning can focus attention on critical values or comparisons.\n",
    "\n",
    "2. **Use Color Purposefully**  \n",
    "   Apply color with intent, not decoration. Neutral tones should dominate, with bold or distinct colors reserved to highlight key data points or categories. This prevents distraction and enhances clarity.\n",
    "\n",
    "3. **Remove Distractions**  \n",
    "   Strip away non-essential chart elements—extra gridlines, borders, redundant labels—so the audience isn’t overwhelmed. Every element should earn its place on the page and reinforce your main message.\n",
    "\n",
    "These strategies help ensure your visualizations communicate insights clearly and efficiently—especially important in time-constrained or high-stakes decision environments."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hcmle-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
