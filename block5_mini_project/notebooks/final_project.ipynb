{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9a99c3e",
   "metadata": {},
   "source": [
    "# Final Project: Gallstone Risk Prediction\n",
    "\n",
    "## 1. Problem & Intended User\n",
    "\n",
    "This project addresses the clinical challenge of **predicting gallstone presence** using physiological and lab-based data. The intended users are:\n",
    "\n",
    "- **Clinicians and decision support systems** seeking interpretable, data-driven insights.\n",
    "- **Public health analysts** evaluating risk markers in patient populations.\n",
    "\n",
    "Accurate prediction can improve screening prioritization, early intervention, and resource allocation, especially in environments where imaging resources are limited.\n",
    "\n",
    "## 2. Data & Exploratory Analysis\n",
    "\n",
    "We used a structured dataset of biometric, clinical, and biochemical features from adult patients. Key steps included:\n",
    "\n",
    "- Handling missing values and categorical encoding.\n",
    "- Identifying class imbalances and feature distributions.\n",
    "- Visualizing correlations and multicollinearity.\n",
    "- Assessing class-conditional feature shifts using boxplots and statistical trends.\n",
    "\n",
    "## 3. Modeling Strategy\n",
    "\n",
    "We compared two supervised classifiers:\n",
    "\n",
    "- **Logistic Regression (baseline)**: for its transparency and interpretability.\n",
    "- **Random Forest (advanced)**: to capture potential non-linear feature interactions.\n",
    "\n",
    "We addressed multicollinearity via **Variance Inflation Factor (VIF)** pruning, scaled inputs using `StandardScaler`, and validated with **5-fold cross-validation**.\n",
    "\n",
    "## 4. Evaluation Results\n",
    "\n",
    "Test set metrics showed:\n",
    "\n",
    "| Metric     | Logistic Regression | Random Forest |\n",
    "|------------|---------------------|----------------|\n",
    "| Accuracy   | 0.750               | 0.703          |\n",
    "| Precision  | 0.767               | 0.724          |\n",
    "| Recall     | 0.719               | 0.656          |\n",
    "| F1 Score   | 0.742               | 0.689          |\n",
    "| ROC AUC    | 0.811               | 0.791          |\n",
    "\n",
    "Logistic Regression outperformed Random Forest on most metrics while offering better interpretability.\n",
    "\n",
    "## 5. Interpretability & Feature Insights\n",
    "\n",
    "- **Top predictors**: `crp_mg_l`, `vitamin_d_ng_ml`, `hyperlipidemia`, and `diabetes`.\n",
    "- **Logistic coefficients** and **tree-based importance scores (MDI, permutation, SHAP)** aligned with clinical expectations.\n",
    "- **SHAP values** supported both global patterns and instance-level explainability.\n",
    "- Overall, explanations were consistent, trustworthy, and user-friendly for clinical integration.\n",
    "\n",
    "## 6. Conclusion\n",
    "\n",
    "The Logistic Regression model offers a **strong balance between performance and interpretability**, making it a viable candidate for low-risk clinical decision support.\n",
    "\n",
    "- Random Forest provides richer modeling capacity but requires **additional interpretability tooling**.\n",
    "- Transparent feature logic and alignment with medical literature build **trust and adoption potential**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2610484f",
   "metadata": {},
   "source": [
    "## Problem & User\n",
    "\n",
    "We aim to interpret machine learning models for predicting **gallstone disease** using a real-world clinical dataset. Our analysis uses the same dataset described in:\n",
    "\n",
    "**Esen İ, Arslan H, Aktürk Esen S, Gülşen M, Kültekin N, Özdemir O.**  \n",
    "*Early prediction of gallstone disease with a machine learning-based method from bioimpedance and laboratory data.*  \n",
    "Medicine. 2024;103(8):e37258.  \n",
    "[https://doi.org/10.1097/MD.0000000000037258](https://doi.org/10.1097/MD.0000000000037258)\n",
    "\n",
    "### Intended Users:\n",
    "- **Clinicians and Analysts** who want interpretable models for early screening of gallstone disease.\n",
    "- **Medical Data Scientists** building diagnostic tools with transparent decision-making processes.\n",
    "- **Public Health Researchers** evaluating population-level predictors of gallstone formation.\n",
    "\n",
    "Our focus is not only to replicate modeling performance, but to **bridge clinical meaning with statistical reasoning**—supporting adoption of ML in medical workflows where **trust and traceability** are essential."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8cb204",
   "metadata": {},
   "source": [
    "## Data and Exploratory Data Analysis (EDA)\n",
    "\n",
    "### Dataset Overview\n",
    "\n",
    "We utilize the same dataset from Esen et al. (2024), which examines early prediction of gallstone disease using clinical, laboratory, and bioimpedance data. The dataset comprises **319 patients** and **40 features**, including demographics, lab values, body composition metrics, and derived outlier flags.\n",
    "\n",
    "> **Citation:**  \n",
    "> Esen İ, Arslan H, Aktürk Esen S, Gülşen M, Kültekin N, Özdemir O.  \n",
    "> *Early prediction of gallstone disease with a machine learning-based method from bioimpedance and laboratory data.*  \n",
    "> Medicine. 2024;103(8):e37258. DOI: [10.1097/MD.0000000000037258](http://dx.doi.org/10.1097/MD.0000000000037258)\n",
    "\n",
    "### Data Structure\n",
    "\n",
    "- **Observations:** 319 patients  \n",
    "- **Features:** 39 predictors + 1 binary target (`has_gallstones`)\n",
    "- **Target Classes:** 0 = No Gallstones, 1 = Gallstones\n",
    "- **Data Types:** Numerical, binary categorical, and derived outlier flags\n",
    "- **Preprocessing:** Categorical columns restored; no missing values remain\n",
    "\n",
    "### Target Class Distribution\n",
    "\n",
    "The target variable is nearly perfectly balanced, which supports fair model training and evaluation without requiring class rebalancing.\n",
    "\n",
    "<div align=\"left\">\n",
    "  <img src=\"../plots/target_distribution.png\" width=\"400\">\n",
    "</div>\n",
    "\n",
    "- **Gallstones:** 161 (50.5%)  \n",
    "- **No Gallstones:** 158 (49.5%)\n",
    "\n",
    "### Distributions of Key Numeric Features\n",
    "\n",
    "We plotted KDE-enhanced histograms to assess each numeric feature's distribution. This revealed that:\n",
    "\n",
    "- **Right-skewed distributions** are common for lab values (e.g., `crp_mg_l`, `glucose_mg_dl`, `triglyceride_mg_dl`)\n",
    "- **Body composition features** are generally near-normal or mildly skewed (e.g., `muscle_mass_kg`, `fat_ratio_percent`)\n",
    "- Outliers in `obesity_percent` were capped at 70% and flagged using `obesity_outlier_flag`\n",
    "\n",
    "### Selected Visualizations\n",
    "\n",
    "<div align=\"left\">\n",
    "  <img src=\"../plots/hist_bmi.png\" width=\"400\">\n",
    "  <img src=\"../plots/hist_hdl_mg_dl.png\" width=\"400\">\n",
    "  <img src=\"../plots/hist_vitamin_d_ng_ml.png\" width=\"400\">\n",
    "</div>\n",
    "\n",
    "### Class-wise Feature Distributions\n",
    "\n",
    "We used boxplots to compare numeric feature values by gallstone status. These plots reveal meaningful clinical and statistical separation.\n",
    "\n",
    "<div align=\"left\">\n",
    "  <img src=\"../plots/boxplot_vitamin_d_ng_ml.png\" width=\"400\">\n",
    "  <img src=\"../plots/boxplot_fat_ratio_percent.png\" width=\"400\">\n",
    "</div>\n",
    "\n",
    "- **Higher in Gallstone Patients**:  \n",
    "  - `bmi`, `fat_ratio_percent`, `crp_mg_l`  \n",
    "- **Lower in Gallstone Patients**:  \n",
    "  - `vitamin_d_ng_ml`, `hdl_mg_dl`  \n",
    "- These align with established metabolic and inflammatory risk patterns.\n",
    "\n",
    "### Correlation Analysis\n",
    "\n",
    "We computed Pearson correlation coefficients between all numeric features and visualized them using a heatmap:\n",
    "\n",
    "<div align=\"left\">\n",
    "  <img src=\"../plots/correlation_matrix.png\" width=\"800\">\n",
    "</div>\n",
    "\n",
    "#### Key Insights:\n",
    "- **Highly correlated clusters**:\n",
    "  - Muscle mass and water content features (e.g., `tbw_kg`, `ecw_kg`, `icw_kg`, `muscle_mass_kg`)\n",
    "  - Fat-related metrics (e.g., `fat_mass_kg`, `fat_ratio_percent`, `bmi`)\n",
    "- **Implications**:\n",
    "  - These redundancies can cause multicollinearity in linear models and were addressed in later modeling steps using VIF-based feature reduction.\n",
    "\n",
    "  ### Summary of EDA Findings\n",
    "\n",
    "| Area                    | Key Insight |\n",
    "|-------------------------|-------------|\n",
    "| **Class Balance**       | 50.5% gallstone-positive, ideal for modeling |\n",
    "| **Feature Shapes**      | Mostly right-skewed labs; body metrics near-normal |\n",
    "| **Class Separation**    | `vitamin_d_ng_ml`, `hdl_mg_dl`, `bmi`, `fat_ratio_percent`, and `crp_mg_l` show strong signal |\n",
    "| **Correlated Features** | Strong clusters suggest redundancy; guide feature pruning |\n",
    "| **Clinical Plausibility** | Trends align with known risk factors, supporting human-centered interpretability |\n",
    "\n",
    "These insights provided the foundation for principled model development and explainability strategies used throughout the project.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1798b5",
   "metadata": {},
   "source": [
    "## Modeling\n",
    "\n",
    "### Objective\n",
    "\n",
    "Build predictive models for gallstone presence using features derived from bioimpedance, laboratory tests, and clinical data. Evaluate both performance and interpretability to guide clinical trust and deployment readiness.\n",
    "\n",
    "### 1. Modeling Strategy\n",
    "\n",
    "We explored two primary modeling approaches:\n",
    "\n",
    "- **Logistic Regression** (Linear Model)\n",
    "  - Prioritized for its simplicity, transparency, and explainability.\n",
    "  - Applied **VIF-based feature pruning** to reduce multicollinearity before training.\n",
    "\n",
    "- **Random Forest Classifier** (Non-linear Model)\n",
    "  - Used to capture complex interactions among features.\n",
    "  - Evaluated for potential performance gain and compared against logistic regression in both accuracy and explainability.\n",
    "\n",
    "### 2. Train/Test Setup\n",
    "\n",
    "- Used an **80/20 stratified split** to preserve class balance during evaluation.\n",
    "- Applied **standard scaling** for the logistic regression pipeline.\n",
    "- Feature selection for Logistic Regression was based on multicollinearity reduction; Random Forest used all features.\n",
    "\n",
    "### 3. Evaluation Metrics\n",
    "\n",
    "Model performance was assessed using:\n",
    "\n",
    "- **Accuracy** – Proportion of correctly predicted labels.\n",
    "- **ROC-AUC** – Area under the receiver operating characteristic curve.\n",
    "- **Precision & Recall** – Class-specific assessment, particularly relevant in healthcare prediction.\n",
    "- **F1 Score** – Harmonic mean of precision and recall.\n",
    "- **Confusion Matrix** – Breakdown of true/false positives and negatives.\n",
    "\n",
    "### 4. Results Overview\n",
    "\n",
    "| Model              | Accuracy | Precision | Recall | F1 Score | ROC AUC |\n",
    "|-------------------|----------|-----------|--------|----------|---------|\n",
    "| Logistic Regression | 0.750    | 0.767     | 0.719  | 0.742    | 0.811   |\n",
    "| Random Forest       | 0.703    | 0.724     | 0.656  | 0.689    | 0.791   |\n",
    "\n",
    "### 5. Summary of Key Modeling Insights\n",
    "\n",
    "- **Logistic Regression** outperformed Random Forest across all metrics on the test set.\n",
    "- It offers **transparent coefficients** and intuitive explanations of feature influence.\n",
    "- **Random Forest**, while flexible and capable of capturing nonlinear patterns, underperformed slightly in both F1 Score and ROC AUC.\n",
    "- Logistic Regression is better suited for this clinical context, where **interpretability and recall** are both essential."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4efba9b4",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "### Objective\n",
    "\n",
    "Evaluate model performance not just in terms of numerical accuracy, but with a focus on **real-world reliability**, **interpretability**, and **clinical relevance**. This includes comparing Logistic Regression and Random Forest across multiple metrics, visualizing results, and analyzing the cost of different types of errors in the healthcare context.\n",
    "\n",
    "### 1. Evaluation Approach\n",
    "\n",
    "- Used a consistent **80/20 stratified split** for fair model comparison.\n",
    "- Applied the same data transformations used during training:\n",
    "  - Logistic Regression used **VIF-pruned and standardized features**.\n",
    "  - Random Forest used the **full original feature set** (no scaling required).\n",
    "- Predictions and probability scores were generated on the test set.\n",
    "- **Cross-validation** (5-fold) was used to assess generalization on the training set.\n",
    "\n",
    "### 2. Performance Metrics (Test Set)\n",
    "\n",
    "| Model              | Accuracy | Precision | Recall | F1 Score | ROC AUC |\n",
    "|-------------------|----------|-----------|--------|----------|---------|\n",
    "| Logistic Regression | 0.750    | 0.767     | 0.719  | 0.742    | 0.811   |\n",
    "| Random Forest       | 0.703    | 0.724     | 0.656  | 0.689    | 0.791   |\n",
    "\n",
    "- **Logistic Regression outperformed Random Forest** across all metrics on the test set.\n",
    "- It also achieved higher **recall**, which is especially critical in healthcare where false negatives are dangerous.\n",
    "- The **ROC AUC** was also higher (0.811 vs. 0.791), indicating better overall discriminative power.\n",
    "\n",
    "### 3. Cross-Validation Results (5-Fold on Training Set)\n",
    "\n",
    "| Model              | Mean ROC AUC (CV) |\n",
    "|-------------------|-------------------|\n",
    "| Logistic Regression | 0.814             |\n",
    "| Random Forest       | 0.841             |\n",
    "\n",
    "- Random Forest slightly outperformed Logistic Regression in cross-validation.\n",
    "- However, its **test performance dropped**, suggesting it may have overfit to the training data.\n",
    "\n",
    "### 4. Visualizations\n",
    "\n",
    "We used two visual diagnostics to assess and communicate model performance:\n",
    "\n",
    "#### Confusion Matrices\n",
    "\n",
    "<div align=\"left\">\n",
    "  <img src=\"../plots/confusion_matrices.png\" width=\"700\">\n",
    "</div>\n",
    "\n",
    "- Logistic Regression produced **fewer false negatives**, a critical benefit in medical screening where missed diagnoses can delay treatment.\n",
    "- Random Forest had slightly more false positives, but also more **false negatives**, making it less suitable for high-stakes use cases like gallstone detection.\n",
    "\n",
    "#### ROC Curves – Gallstones Detection\n",
    "\n",
    "<div align=\"left\">\n",
    "  <img src=\"../plots/roc_curves_inline_labels.png\" width=\"600\">\n",
    "</div>\n",
    "\n",
    "- **Logistic Regression** achieved the highest AUC (**0.81**) and exhibited more favorable calibration.\n",
    "- ROC curves were styled for clarity, with **inline model labels** and a clean diagonal reference line.\n",
    "\n",
    "### 5. Error Trade-Offs in Clinical Context\n",
    "\n",
    "- **False Negatives** (missed gallstone cases) carry higher clinical risk than false positives.\n",
    "- This makes **recall a priority**, and Logistic Regression had the highest recall (0.719).\n",
    "- False positives lead to extra imaging, but false negatives could delay treatment and lead to complications.\n",
    "\n",
    "### 6. Clinical Interpretability\n",
    "\n",
    "- Top predictors like `crp_mg_l`, `vitamin_d_ng_ml`, and `alt_u_l` are **clinically plausible** and align with known risk factors.\n",
    "- Logistic Regression’s coefficient transparency supports **decision support** adoption in medical workflows.\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "Logistic Regression emerged as the more **trustworthy, interpretable, and clinically appropriate** model despite Random Forest’s slight edge in cross-validation. It provides consistent performance, better recall, and transparent reasoning—making it well-suited for deployment in real-world diagnostic settings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c80c04",
   "metadata": {},
   "source": [
    "\n",
    "## Interpretation\n",
    "\n",
    "This section focuses on how both models—**Logistic Regression** and **Random Forest**—arrive at their predictions. We use interpretable techniques and professional-quality visuals to understand which features most influence predictions and whether the models are aligned with real-world clinical reasoning.\n",
    "\n",
    "### Logistic Regression Coefficients\n",
    "\n",
    "The coefficients represent the **direction** and **strength** of influence for each input feature:\n",
    "\n",
    "- **Positive Coefficient → Increased Gallstone Risk**\n",
    "- **Negative Coefficient → Decreased Gallstone Risk**\n",
    "\n",
    "<div align=\"left\">\n",
    "  <img src=\"../plots/logreg_feature_importance.png\" width=\"650\">\n",
    "</div>\n",
    "\n",
    "#### Notable Features:\n",
    "- `crp_mg_l` (C-reactive protein) ↑ — confirms inflammation is a strong gallstone signal\n",
    "- `hyperlipidemia` ↑ and `diabetes` ↑ — metabolic conditions associated with higher risk\n",
    "- `vitamin_d_ng_ml` ↓ — supports recent findings linking deficiency to gallbladder dysfunction\n",
    "- `ast_u_l` ↓ — mild protective signal, consistent with preserved liver health\n",
    "\n",
    "These **directional, transparent** coefficients are critical for clinicians who need to **understand and trust model logic**.\n",
    "\n",
    "### Random Forest Interpretability\n",
    "\n",
    "To peek inside the Random Forest, we computed:\n",
    "\n",
    "- **MDI** – how often a feature splits the data\n",
    "- **Permutation Importance** – performance drop when a feature is shuffled\n",
    "- **SHAP Values** – per-prediction explanations grounded in game theory\n",
    "\n",
    "<div align=\"left\">\n",
    "  <img src=\"../plots/rf_feature_importances_combined.png\" width=\"800\">\n",
    "</div>\n",
    "\n",
    "#### Key Findings:\n",
    "- `crp_mg_l` ranked top across all methods\n",
    "- `vitamin_d_ng_ml`, `ast_u_l`, `ecf_tbw_ratio_index`, and `fat_ratio_percent` were frequent top contributors\n",
    "- These results **corroborate** findings from logistic regression and highlight Random Forest’s robustness\n",
    "\n",
    "### Clinical Relevance and Trust\n",
    "\n",
    "| Feature                 | Clinical Significance                                      | Model Signal |\n",
    "|-------------------------|------------------------------------------------------------|--------------|\n",
    "| CRP                    | Inflammatory marker for gallbladder disease                | ↑ Strong     |\n",
    "| Vitamin D              | Linked to bile function and motility                        | ↓ Moderate   |\n",
    "| AST / ALT              | Liver function indicators                                   | ↓ Moderate   |\n",
    "| Hyperlipidemia         | Part of the metabolic syndrome                              | ↑ Moderate   |\n",
    "| ECF/TBW Ratio          | Marker of fluid distribution, may reflect bile composition  | ↑ Mild       |\n",
    "\n",
    "Both models surfaced **medically plausible** predictors, increasing confidence in model use.\n",
    "\n",
    "### Interpretability Summary\n",
    "\n",
    "| Aspect               | Logistic Regression                | Random Forest                         |\n",
    "|----------------------|-------------------------------------|----------------------------------------|\n",
    "| Transparency         | ✅ High (direct coefficients)       | ➖ Medium (SHAP + permutation help)     |\n",
    "| Clinical Alignment   | ✅ Excellent                        | ✅ Strong                               |\n",
    "| Trustworthiness      | ✅ Ready for clinical decision aid  | ➕ With visual support                  |\n",
    "\n",
    "Logistic Regression offers an intuitive explanation path, while Random Forest—despite its complexity—can be made interpretable with proper tools.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2803d595",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Over the course of this mini-project, we completed an end-to-end machine learning workflow using a real-world clinical dataset from *Esen et al. (2024)* on early prediction of gallstone disease. The goal was to build interpretable models that could support clinicians in risk stratification based on laboratory and bioimpedance features.\n",
    "\n",
    "### Key Accomplishments\n",
    "- **Data Cleaning & Preparation**: We addressed missing values, corrected data types, removed outliers, and engineered clinically relevant features. VIF pruning was applied to reduce multicollinearity for linear modeling.\n",
    "- **Exploratory Data Analysis (EDA)**: Visual and statistical exploration revealed class imbalance, key feature distributions, and correlations that informed downstream modeling choices.\n",
    "- **Modeling**: We trained both **Logistic Regression** (with standardized, reduced features) and **Random Forest** (on full data), optimizing for generalization and interpretability.\n",
    "- **Evaluation**: Logistic Regression achieved superior test-set performance (ROC AUC = 0.811) and higher recall, making it the safer model for minimizing false negatives in a clinical context.\n",
    "- **Interpretability**: Feature attribution using coefficients, SHAP, and permutation importance confirmed that top predictors like `crp_mg_l`, `vitamin_d_ng_ml`, and `hyperlipidemia` were both statistically strong and clinically meaningful.\n",
    "- **Communication**: Visuals were created using *Storytelling with Data* design principles to clearly convey findings to technical and non-technical stakeholders alike.\n",
    "\n",
    "### Final Takeaways\n",
    "- **Logistic Regression** is a trustworthy baseline for clinical deployment: interpretable, generalizable, and well-aligned with domain knowledge.\n",
    "- **Random Forest**, augmented with SHAP and permutation methods, provides richer modeling capacity but requires additional interpretive support for user trust.\n",
    "- This project exemplifies responsible machine learning by balancing **performance, interpretability, and usability** in a sensitive healthcare application.\n",
    "\n",
    "The structured, reproducible approach demonstrated here reflects key skills in human-centered ML engineering: combining rigorous data science with empathy for end users and their real-world decision contexts."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
