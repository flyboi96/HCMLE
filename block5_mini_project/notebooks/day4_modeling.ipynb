{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d3efe65",
   "metadata": {},
   "source": [
    "# 📘 Day 4: Baseline Modeling & Feature Insights\n",
    "\n",
    "## 1. Objective  \n",
    "Train two different models, assess multicollinearity, and explore feature importance. Identify which features are most predictive, which are redundant, and how model choices affect interpretability and performance.\n",
    "\n",
    "## 2. Key Steps  \n",
    "- Split data into training and test sets  \n",
    "- Assess multicollinearity using correlation matrix and Variance Inflation Factor (VIF)  \n",
    "- Drop or consolidate highly correlated features if necessary  \n",
    "- Train a baseline model (e.g., Logistic Regression)  \n",
    "- Train a more advanced model (e.g., Random Forest or Gradient Boosting)  \n",
    "- Extract and interpret feature importances  \n",
    "- Compare model performance and explainability  \n",
    "- Save models for reuse  \n",
    "- Read PAIR Guidebook: “Explainability + Trust” (Chapter)\n",
    "\n",
    "## 3. Results  \n",
    "- Two models trained and saved  \n",
    "- Multicollinearity addressed with VIF and correlation pruning  \n",
    "- Key feature insights extracted  \n",
    "- Initial model performance evaluated and compared\n",
    "\n",
    "## 4. Summary  \n",
    "- Logistic Regression provides strong interpretability and fast training  \n",
    "- Tree-based model offers flexible non-linear performance  \n",
    "- Top predictors identified across models  \n",
    "- Next step: refine model and validate across folds (Day 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e254274",
   "metadata": {},
   "source": [
    "## Load Cleaned Dataset & Restore Data Types\n",
    "\n",
    "We begin by loading the cleaned dataset and restoring categorical data types. This ensures that binary indicators, class labels, and flags are treated appropriately by modeling pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7416d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the cleaned dataset\n",
    "df = pd.read_csv(\"../data/cleaned.csv\")\n",
    "\n",
    "# Restore categorical data types\n",
    "categorical_cols = [\n",
    "    # Original binary or ordinal clinical features\n",
    "    \"gender\",\n",
    "    \"comorbidity\",\n",
    "    \"cad\",\n",
    "    \"hypothyroidism\",\n",
    "    \"hyperlipidemia\",\n",
    "    \"diabetes\",\n",
    "    \"hepatic_fat\",\n",
    "    \"has_gallstones\",\n",
    "\n",
    "    # Outlier flags (created during data cleaning)\n",
    "    \"glucose_outlier_flag\",\n",
    "    \"obesity_outlier_flag\",\n",
    "    \"muscle_mass_outlier_flag\",\n",
    "    \"gfr_outlier_flag\",\n",
    "    \"tbw_outlier_flag\",\n",
    "    \"icw_outlier_flag\",\n",
    "    \"vfr_outlier_flag\",\n",
    "    \"ldl_outlier_flag\",\n",
    "    \"hdl_outlier_flag\",\n",
    "    \"triglyceride_outlier_flag\",\n",
    "    \"alt_outlier_flag\",\n",
    "    \"crp_outlier_flag\"\n",
    "]\n",
    "\n",
    "for col in categorical_cols:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].astype(\"category\")\n",
    "\n",
    "# Confirm restored types\n",
    "df.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca4eb1e",
   "metadata": {},
   "source": [
    "## Train-Test Split\n",
    "\n",
    "We split the cleaned dataset into an 80/20 training and testing set using `train_test_split`, with stratification to maintain class balance in `has_gallstones`. This ensures reliable model evaluation while preserving the distribution of the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c737005d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define target and features\n",
    "target = \"has_gallstones\"\n",
    "y = df[target].replace({1: \"Gallstones\", 0: \"No Gallstones\"})\n",
    "X = df.drop(columns=[target])\n",
    "\n",
    "# Stratified train/test split (preserves class distribution)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "# Confirm shapes\n",
    "print(f\"X_train: {X_train.shape}, X_test: {X_test.shape}\")\n",
    "print(f\"y_train: {y_train.shape}, y_test: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6173a912",
   "metadata": {},
   "source": [
    "## Multicollinearity Check\n",
    "\n",
    "To detect multicollinearity, we used:\n",
    "- **Correlation matrix** to visualize strong linear relationships between features.\n",
    "- **Variance Inflation Factor (VIF)** to quantify redundancy.\n",
    "\n",
    "### VIF Interpretation:\n",
    "- **VIF > 10**: Strong multicollinearity – feature may need to be dropped or combined.\n",
    "- **VIF 5–10**: Moderate multicollinearity – worth reviewing contextually.\n",
    "- **VIF < 5**: Generally acceptable.\n",
    "\n",
    "We will use this analysis to inform feature selection and avoid unstable model behavior in linear modeling workflows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92761556",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Compute correlation matrix on numeric features only\n",
    "corr_matrix = X_train.select_dtypes(include=[\"float64\", \"int64\"]).corr()\n",
    "\n",
    "# Plot heatmap\n",
    "plt.figure(figsize=(14, 12))\n",
    "sns.heatmap(corr_matrix, annot=False, cmap=\"coolwarm\", center=0)\n",
    "plt.title(\"Correlation Matrix (Training Set)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../plots/corr_matrix.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526f0bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import pandas as pd\n",
    "\n",
    "# Subset only numeric features for VIF\n",
    "numeric_features = X_train.select_dtypes(include=[\"float64\", \"int64\"])\n",
    "numeric_feature_names = numeric_features.columns\n",
    "\n",
    "# Compute VIF\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"feature\"] = numeric_feature_names\n",
    "vif_data[\"vif\"] = [variance_inflation_factor(numeric_features.values, i)\n",
    "                   for i in range(numeric_features.shape[1])]\n",
    "\n",
    "# Sort and display\n",
    "vif_data = vif_data.sort_values(\"vif\", ascending=False)\n",
    "vif_data.reset_index(drop=True, inplace=True)\n",
    "display(vif_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324107fc",
   "metadata": {},
   "source": [
    "## Multicollinearity Assessment – VIF Results\n",
    "\n",
    "We calculated Variance Inflation Factors (VIF) for all numeric features in the training set to quantify multicollinearity. VIF measures how much a feature is linearly predicted by the other features; values above 10 indicate problematic redundancy.\n",
    "\n",
    "### Summary of Findings\n",
    "\n",
    "- **Extremely high VIFs** were observed in many **body composition metrics**, particularly:\n",
    "  - `height_cm`: **8775**\n",
    "  - `weight_kg`: **7089**\n",
    "  - `lean_mass_percent`: **3917**\n",
    "  - `ecf_tbw_ratio_index`: **3271**\n",
    "  - `bmi`, `muscle_mass_kg`, and `tbw_kg` also exceed **1000**\n",
    "\n",
    "- These features are **highly intercorrelated** due to shared dependence on body size and water/fat mass — unsurprising for bioimpedance-derived data.\n",
    "\n",
    "- Additional features with **VIF > 100** include:\n",
    "  - `cholesterol_total_mg_dl`\n",
    "  - `hemoglobin_g_dl`\n",
    "  - `gfr_ml_min`\n",
    "  - `age`\n",
    "\n",
    "These should be reviewed closely for potential consolidation or removal before using **linear models**.\n",
    "\n",
    "- **Low multicollinearity** was found in:\n",
    "  - `vitamin_d_ng_ml`, `crp_mg_l`, `ast_u_l`, `triglyceride_mg_dl`, `glucose_mg_dl`, `obesity_percent`, and others — all had **VIF < 10**, indicating safe inclusion.\n",
    "\n",
    "### Action Plan\n",
    "\n",
    "- For the **baseline logistic regression**, we will drop or consolidate highly collinear variables to stabilize coefficient estimates and improve interpretability.\n",
    "- For the **tree-based model**, we may retain correlated features, as trees are less sensitive to multicollinearity.\n",
    "\n",
    "This step ensures our models are both statistically valid and human-interpretable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e861ec5",
   "metadata": {},
   "source": [
    "## Variance Inflation Factor (VIF)–Based Feature Pruning\n",
    "\n",
    "To mitigate multicollinearity in our dataset, we implemented an **iterative VIF reduction procedure**. Variance Inflation Factor quantifies how much a predictor is linearly explained by the other predictors. High VIF values (typically >10) suggest severe multicollinearity, which can inflate coefficient variance, obscure interpretation, and undermine model generalizability—especially in linear models.\n",
    "\n",
    "The process follows these steps:\n",
    "\n",
    "1. Compute VIF for all numeric predictors.\n",
    "2. Iteratively remove the feature with the highest VIF score.\n",
    "3. Recompute VIF until all remaining features fall below a conservative threshold (`VIF < 10`).\n",
    "4. Return a reduced, more stable feature set for modeling.\n",
    "5. Apply the same column drops to the test set for consistency.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9db5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import pandas as pd\n",
    "\n",
    "def calculate_vif(X):\n",
    "    vif_data = pd.DataFrame()\n",
    "    vif_data[\"feature\"] = X.columns\n",
    "    vif_data[\"vif\"] = [\n",
    "        variance_inflation_factor(X.values, i)\n",
    "        for i in range(X.shape[1])\n",
    "    ]\n",
    "    return vif_data.sort_values(\"vif\", ascending=False)\n",
    "\n",
    "# Start with numeric features only\n",
    "X_vif = X_train.select_dtypes(include=[\"float64\", \"int64\"]).copy()\n",
    "\n",
    "vif_threshold = 10\n",
    "features_dropped = []\n",
    "\n",
    "while True:\n",
    "    vif_df = calculate_vif(X_vif)\n",
    "    max_vif = vif_df[\"vif\"].max()\n",
    "\n",
    "    if max_vif < vif_threshold:\n",
    "        break\n",
    "\n",
    "    # Drop feature with highest VIF\n",
    "    feature_to_drop = vif_df.iloc[0][\"feature\"]\n",
    "    features_dropped.append(feature_to_drop)\n",
    "    X_vif.drop(columns=feature_to_drop, inplace=True)\n",
    "\n",
    "# Final VIF results\n",
    "final_vif_df = calculate_vif(X_vif)\n",
    "\n",
    "# Outputs\n",
    "print(\"Dropped features due to high VIF:\")\n",
    "print(features_dropped)\n",
    "\n",
    "print(f\"\\nRemaining features ({len(final_vif_df)} total):\")\n",
    "print(final_vif_df.to_string(index=False))\n",
    "\n",
    "# Apply reduction to original splits\n",
    "X_train_reduced = X_train.drop(columns=features_dropped)\n",
    "X_test_reduced = X_test.drop(columns=features_dropped)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2f96cc",
   "metadata": {},
   "source": [
    "## VIF-Based Multicollinearity Pruning – Results & Interpretation\n",
    "\n",
    "### Features Removed (23 total)\n",
    "High-VIF features removed due to excessive collinearity:\n",
    "```\n",
    "['height_cm', 'weight_kg', 'ecf_tbw_ratio_index', 'muscle_mass_kg',\n",
    " 'lean_mass_percent', 'bmi', 'ecw_kg', 'tbw_kg', 'icw_kg', 'fat_mass_kg',\n",
    " 'visceral_muscle_mass_kg', 'cholesterol_total_mg_dl', 'hemoglobin_g_dl',\n",
    " 'bone_mass_kg', 'protein_percent', 'visceral_fat_area_cm2',\n",
    " 'fat_ratio_percent', 'age', 'gfr_ml_min', 'creatinine_mg_dl',\n",
    " 'ldl_mg_dl', 'vfr_score', 'alp_u_l']\n",
    "```\n",
    "\n",
    "Many of these are physiologically interdependent (e.g., BMI and fat mass; TBW and ICW/ECW) and thus redundant. Their exclusion strengthens numerical conditioning without compromising signal diversity.\n",
    "\n",
    "---\n",
    "\n",
    "### Final Selected Features (8 total)\n",
    "\n",
    "| Feature               | VIF     |\n",
    "|------------------------|---------|\n",
    "| `ast_u_l`              | 8.48    |\n",
    "| `alt_u_l`              | 8.22    |\n",
    "| `glucose_mg_dl`        | 7.59    |\n",
    "| `hdl_mg_dl`            | 7.12    |\n",
    "| `vitamin_d_ng_ml`      | 4.47    |\n",
    "| `triglyceride_mg_dl`   | 4.21    |\n",
    "| `obesity_percent`      | 3.34    |\n",
    "| `crp_mg_l`             | 1.15    |\n",
    "\n",
    "These retained predictors span liver function, glucose regulation, inflammation, and adiposity—physiologically diverse yet statistically independent.\n",
    "\n",
    "---\n",
    "\n",
    "### Analysis\n",
    "\n",
    "- **Statistical Validity**: VIF-based pruning aligns with standard regression diagnostics to avoid unstable or misleading coefficient estimates. Reducing multicollinearity lowers the condition number of the design matrix, improving numerical reliability in linear solvers.\n",
    "\n",
    "- **Interpretability Preservation**: Unlike PCA or regularization, this method retains **human-readable, domain-relevant features**, making it ideal for stakeholder-facing models (e.g., clinical settings).\n",
    "\n",
    "- **Physiological Orthogonality**: Final features represent **distinct biological systems** (e.g., hepatic markers vs. metabolic markers) and minimize domain overlap, reducing the risk of informational redundancy.\n",
    "\n",
    "- **Bias-Variance Balance**: While removing collinear features may discard some raw predictive power, it significantly reduces overfitting risk and improves generalization for smaller datasets.\n",
    "\n",
    "- **Downstream Compatibility**: This filtered feature set is especially well-suited for **linear baseline models**. For tree-based methods, all features could be reintroduced without multicollinearity concerns.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14487516",
   "metadata": {},
   "source": [
    "## Baseline Model: Logistic Regression\n",
    "\n",
    "We begin modeling with a **Logistic Regression classifier**, a commonly used baseline for binary classification tasks. Logistic regression is favored for its simplicity, interpretability, and probabilistic outputs. By training it on our VIF-pruned feature set (`X_train_reduced`), we establish a performance reference point to compare against more complex models.\n",
    "\n",
    "The following steps will be performed:\n",
    "- Fit a logistic regression model on the training data\n",
    "- Predict on the test data\n",
    "- Evaluate with accuracy, precision, recall, F1-score, and ROC AUC\n",
    "- Analyze coefficients to interpret feature contributions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8310e8e",
   "metadata": {},
   "source": [
    "### Scaled Logistic Regression with Performance Visualization\n",
    "\n",
    "We train a logistic regression model on standardized input features to mitigate the effects of differing variable scales. After fitting the model, we assess its performance using a classification report, a confusion matrix heatmap, and the ROC AUC score to understand both classification accuracy and probability calibration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc0cf14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_reduced)\n",
    "X_test_scaled = scaler.transform(X_test_reduced)\n",
    "\n",
    "# Fit logistic regression on scaled data\n",
    "logreg = LogisticRegression(max_iter=1000, random_state=42)\n",
    "logreg.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = logreg.predict(X_test_scaled)\n",
    "y_proba = logreg.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion matrix\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", \n",
    "            xticklabels=logreg.classes_, yticklabels=logreg.classes_)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Confusion Matrix – Logistic Regression\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ROC AUC\n",
    "roc_auc = roc_auc_score(y_test, y_proba)\n",
    "print(f\"ROC AUC: {roc_auc:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdeb6c91",
   "metadata": {},
   "source": [
    "## Logistic Regression Performance Summary (Scaled Features)\n",
    "\n",
    "The logistic regression model, trained on standardized inputs, demonstrated **solid baseline performance** in predicting gallstone status.\n",
    "\n",
    "### Key Metrics:\n",
    "- **Accuracy**: 75% overall\n",
    "- **Precision/Recall**:\n",
    "  - Gallstones: precision = 0.77, recall = 0.72\n",
    "  - No Gallstones: precision = 0.74, recall = 0.78\n",
    "- **F1-score**: Balanced at ~0.75 across both classes\n",
    "- **ROC AUC**: 0.811 — strong discriminative ability for a linear model\n",
    "\n",
    "### Confusion Matrix Insights:\n",
    "- True positives and true negatives are well-represented (23 and 25, respectively).\n",
    "- Misclassifications are balanced across classes, indicating no strong bias.\n",
    "- This balanced behavior enhances trust in clinical screening contexts.\n",
    "\n",
    "### Conclusion:\n",
    "Logistic regression provides a **well-calibrated, interpretable model** with good generalization to unseen data. It serves as an excellent baseline to evaluate more complex, potentially less interpretable models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f5ebf4",
   "metadata": {},
   "source": [
    "## Logistic Regression Coefficients\n",
    "\n",
    "To interpret the logistic regression model, we extract the learned coefficients associated with each feature. These coefficients represent the **log-odds** change in the probability of gallstones for a one-unit increase in the feature, holding all other variables constant.\n",
    "\n",
    "This helps us understand which features push the model’s prediction toward or away from gallstone presence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0893b85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Model classes:\", logreg.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400f284c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Create a DataFrame of coefficients\n",
    "coef_df = pd.DataFrame({\n",
    "    \"Feature\": X_train_reduced.columns,\n",
    "    \"Coefficient\": -logreg.coef_[0]\n",
    "})\n",
    "\n",
    "# Add direction (positive = higher risk, negative = lower risk)\n",
    "coef_df[\"Odds Impact\"] = np.where(coef_df[\"Coefficient\"] > 0, \"Increased Gallstone Risk\", \"Decreased Gallstone Risk\")\n",
    "\n",
    "# Sort by absolute value of coefficient\n",
    "coef_df[\"Abs_Coefficient\"] = coef_df[\"Coefficient\"].abs()\n",
    "coef_df = coef_df.sort_values(\"Abs_Coefficient\", ascending=False).drop(columns=\"Abs_Coefficient\")\n",
    "\n",
    "# Display\n",
    "coef_df.reset_index(drop=True, inplace=True)\n",
    "coef_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02866e20",
   "metadata": {},
   "source": [
    "## 🔍 Coefficient Analysis – Logistic Regression\n",
    "\n",
    "The logistic regression model provides interpretable coefficients that reflect the **log-odds change** of gallstone risk for a unit increase in each feature, holding others constant. Positive coefficients indicate increased risk, while negative coefficients indicate protective effects.\n",
    "\n",
    "### Top Insights:\n",
    "\n",
    "- `crp_mg_l` has the **strongest positive coefficient**, suggesting that higher inflammation levels (as measured by CRP) are **strongly associated** with increased odds of gallstones. This supports the hypothesis that low-grade inflammation may play a role in gallstone formation.\n",
    "\n",
    "- `vitamin_d_ng_ml` and `hyperlipidemia` also have **positive coefficients**, indicating that **higher vitamin D** levels and the presence of **elevated lipids** are associated with increased gallstone risk in this cohort — though the vitamin D result may contradict some prior studies and warrants scrutiny.\n",
    "\n",
    "- `diabetes` and `comorbidity` diverge in direction: \n",
    "  - `diabetes` has a **positive coefficient**, aligning with known metabolic risk factors.\n",
    "  - `comorbidity` has a **negative coefficient**, which is **counterintuitive**; this may reflect coding artifacts or interactions that need further exploration.\n",
    "\n",
    "- `obesity_percent` and `alt_u_l` both show **negative coefficients**, suggesting that **greater obesity %** and **elevated liver enzymes** are associated with **lower** odds of gallstones in this model — a finding that likely reflects multicollinearity or residual confounding rather than true causality.\n",
    "\n",
    "- `hdl_mg_dl`, typically considered protective, shows a **positive coefficient** — indicating higher HDL is associated with **increased** gallstone risk in this data. This unexpected result should be interpreted cautiously and may again reflect population structure or correlated inputs.\n",
    "\n",
    "- Outlier flags such as `alt_outlier_flag`, `glucose_outlier_flag`, and `ldl_outlier_flag` appear in both directions, suggesting potential **nonlinear effects** or noise from how these were encoded.\n",
    "\n",
    "### Summary:\n",
    "\n",
    "- Many of the top features identified by logistic regression **align with clinical expectations** (e.g., inflammation, diabetes), while others show **unexpected signs** that should not be taken at face value due to potential confounding or high collinearity.\n",
    "\n",
    "- These findings reinforce the importance of:\n",
    "  - Validating insights with tree-based models or external data\n",
    "  - Revisiting preprocessing decisions (e.g., encoding, scaling)\n",
    "  - Interpreting logistic coefficients within the context of correlation structure and sample size\n",
    "\n",
    "The logistic regression remains a helpful baseline, especially for understanding **directional trends** and feature contribution when interpretability is critical."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38bef05e",
   "metadata": {},
   "source": [
    "### Logistic Regression Coefficient Analysis\n",
    "\n",
    "This coefficient table offers insight into how individual features influence gallstone risk:\n",
    "\n",
    "- **Strongest predictors** (by magnitude) include:\n",
    "  - **`crp_mg_l` (C-reactive protein)**: Strong negative coefficient (−1.51), suggesting that higher inflammation is surprisingly associated with *lower* predicted risk. This may reflect confounding or data imbalance and deserves scrutiny.\n",
    "  - **`vitamin_d_ng_ml`**: Positive association with gallstones, contradicting some clinical expectations — possibly due to supplement use or data artifacts.\n",
    "  - **`hyperlipidemia`** and **`diabetes`**: Show expected trends of *decreased* and *increased* gallstone risk, respectively.\n",
    "\n",
    "- **Outlier flags** (e.g., `alt_outlier_flag`, `gfr_outlier_flag`) contribute meaningfully, reinforcing the importance of edge-case detection in prediction.\n",
    "\n",
    "- **Sociodemographic and clinical variables** like `gender`, `comorbidity`, and `obesity_percent` show moderate impact, with obesity increasing risk and gender yielding a small negative effect.\n",
    "\n",
    "- Several features have **minimal or ambiguous coefficients**, including `tbw_outlier_flag`, `hdl_outlier_flag`, and `triglyceride_mg_dl`, suggesting limited predictive utility in this model.\n",
    "\n",
    "Overall, the model assigns interpretable weights to features and outliers, enabling human-aligned insights. However, the unexpected signs (e.g., `crp_mg_l`) warrant follow-up, possibly with regularization, feature interactions, or nonlinear models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a06ee33",
   "metadata": {},
   "source": [
    "## Train and Evaluate Random Forest Classifier\n",
    "\n",
    "We train a Random Forest model on the full feature set, including multicollinear variables. As a tree-based ensemble, Random Forests are robust to multicollinearity and can capture complex, non-linear interactions between predictors. We assess its performance using classification metrics, a confusion matrix, and ROC AUC to compare against the logistic regression baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40fcdc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Train Random Forest on original (unpruned, unscaled) features\n",
    "rf = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "y_proba_rf = rf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Classification report\n",
    "print(\"Random Forest Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_rf))\n",
    "\n",
    "# Confusion matrix\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "cm_rf = confusion_matrix(y_test, y_pred_rf)\n",
    "sns.heatmap(cm_rf, annot=True, fmt=\"d\", cmap=\"Greens\", \n",
    "            xticklabels=rf.classes_, yticklabels=rf.classes_)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Confusion Matrix – Random Forest\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ROC AUC\n",
    "roc_auc_rf = roc_auc_score(y_test, y_proba_rf)\n",
    "print(f\"ROC AUC: {roc_auc_rf:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3bb5ca4",
   "metadata": {},
   "source": [
    "## Random Forest Performance Summary\n",
    "\n",
    "The Random Forest model demonstrated decent classification ability, though it underperformed slightly compared to the logistic regression baseline in terms of ROC AUC.\n",
    "\n",
    "### Key Metrics:\n",
    "- **Accuracy**: 70%\n",
    "- **ROC AUC**: 0.791 (vs. 0.811 for Logistic Regression)\n",
    "- **Gallstones class (positive class)**:\n",
    "  - Precision: 0.72\n",
    "  - Recall: 0.66\n",
    "  - F1-score: 0.69\n",
    "\n",
    "### Interpretation:\n",
    "- The model shows **moderate discriminative power**, with relatively balanced performance across classes.\n",
    "- **Recall was lower for gallstones (0.66)** compared to logistic regression (0.72), indicating more false negatives in the Random Forest.\n",
    "- **ROC AUC of 0.791** suggests the model is still reasonably good at ranking predictions, but not superior to the simpler baseline.\n",
    "\n",
    "### Implications:\n",
    "- Despite Random Forest’s capacity to model complex feature interactions, its performance gain was limited — likely due to:\n",
    "  - High feature redundancy\n",
    "  - Small sample size (n = 64 test observations)\n",
    "- Logistic Regression may still be the **preferred model** if interpretability and generalization are priorities.\n",
    "- Random Forest should still be considered if future data expansions or nonlinear patterns are expected to become more influential.\n",
    "\n",
    "We will now explore **feature importances** to better understand what drove Random Forest predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5e8b47",
   "metadata": {},
   "source": [
    "## Feature Importance Analysis – Random Forest\n",
    "\n",
    "Understanding which features drive model predictions is essential for interpretability and stakeholder trust. Random Forests expose this directly via their built-in `.feature_importances_` attribute, which reflects the relative contribution of each feature to the model’s decision-making.\n",
    "\n",
    "We’ll visualize and rank the top contributors using the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7822196",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Retrieve feature importances\n",
    "importances = rf.feature_importances_\n",
    "feature_names = X_train.columns\n",
    "feature_df = pd.DataFrame({\n",
    "    \"Feature\": feature_names,\n",
    "    \"Importance\": importances\n",
    "}).sort_values(\"Importance\", ascending=False)\n",
    "\n",
    "# Plot top features with hue workaround to avoid deprecation warning\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.barplot(\n",
    "    data=feature_df.head(10),\n",
    "    x=\"Importance\",\n",
    "    y=\"Feature\",\n",
    "    hue=\"Feature\",           # Assign hue to avoid future warning\n",
    "    palette=\"Greens_r\",\n",
    "    dodge=False,\n",
    "    legend=False             # Suppress redundant legend\n",
    ")\n",
    "plt.title(\"Top 10 Feature Importances – Random Forest\")\n",
    "plt.xlabel(\"Relative Importance\")\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../plots/random_forest_feature_importances.png\")\n",
    "plt.show()\n",
    "\n",
    "# Optionally: display all ranked importances\n",
    "feature_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80fad947",
   "metadata": {},
   "source": [
    "## Feature Importance Interpretation – Random Forest\n",
    "\n",
    "We examined the top 10 features ranked by their relative importance in the Random Forest classifier. Feature importance reflects how much a given variable contributes to reducing impurity across all trees in the ensemble.\n",
    "\n",
    "### Key Observations\n",
    "\n",
    "- **crp_mg_l** (C-Reactive Protein) emerged as the **most predictive feature**, aligning with its known role in inflammatory processes. Its dominant importance suggests gallstones may correlate with low-grade or acute inflammation.\n",
    "- **vitamin_d_ng_ml** was the second most important feature, consistent with prior boxplot analysis. This reinforces its potential as a biologically relevant risk factor.\n",
    "- Liver enzymes like **ast_u_l** also ranked highly, suggesting subtle hepatic signals may influence predictions.\n",
    "- Hydration-related features such as **ecf_tbw_ratio_index** and **ecw_kg** contribute meaningfully, indicating possible body fluid composition effects.\n",
    "- Body composition features including **fat_ratio_percent**, **fat_mass_kg**, and **lean_mass_percent** show up as moderate predictors, supporting the obesity-related patterns seen in EDA.\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "These importance rankings provide valuable insight into how the model learns from the data:\n",
    "- Inflammatory and metabolic markers (e.g., CRP, Vitamin D, AST) are prioritized over purely structural variables like height or weight.\n",
    "- Several features identified as important were previously dropped due to high multicollinearity (e.g., fat mass, lean mass), suggesting a **trade-off between feature independence and predictive strength**.\n",
    "\n",
    "These insights guide both feature selection and model interpretation, offering a foundation for stakeholder explanations and model transparency."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b361bc",
   "metadata": {},
   "source": [
    "## Model Comparison: Performance vs. Explainability\n",
    "\n",
    "We evaluated two modeling approaches—**Logistic Regression** and **Random Forest**—to balance predictive performance with interpretability in predicting gallstone presence.\n",
    "\n",
    "### Logistic Regression (Baseline Model)\n",
    "- **Accuracy:** 75%\n",
    "- **ROC AUC:** 0.811\n",
    "- **Key Strengths:**\n",
    "  - Transparent: coefficients directly reflect feature impact on log-odds.\n",
    "  - Efficient: fast to train and deploy.\n",
    "  - Interpretable: suitable for clinical settings where **explanation matters**.\n",
    "- **Limitations:**\n",
    "  - Assumes linear relationships between inputs and log-odds.\n",
    "  - May underperform when feature interactions or nonlinearities are important.\n",
    "\n",
    "### Random Forest (Advanced Model)\n",
    "- **Accuracy:** 70%\n",
    "- **ROC AUC:** 0.791\n",
    "- **Key Strengths:**\n",
    "  - Captures nonlinear relationships and complex interactions.\n",
    "  - More robust to outliers and overfitting with small tweaks.\n",
    "  - Identifies **feature importances** without assuming a specific model structure.\n",
    "- **Limitations:**\n",
    "  - Less interpretable: individual predictions are opaque without tools like SHAP.\n",
    "  - Slightly lower ROC AUC and accuracy in this dataset compared to logistic regression.\n",
    "  - Higher computational cost and deployment complexity.\n",
    "\n",
    "### Comparative Summary\n",
    "\n",
    "| Metric           | Logistic Regression | Random Forest     |\n",
    "|------------------|---------------------|-------------------|\n",
    "| Accuracy         | 75%                 | 70%               |\n",
    "| ROC AUC          | 0.811               | 0.791             |\n",
    "| Interpretability | High                | Moderate–Low      |\n",
    "| Training Time    | Fast                | Moderate          |\n",
    "| Feature Insight  | Direct (coefficients) | Indirect (importance scores) |\n",
    "\n",
    "### Takeaway\n",
    "\n",
    "- Logistic regression slightly outperformed random forest in this case, both in **accuracy and ROC AUC**.\n",
    "- Given its high interpretability and competitive performance, logistic regression may be **preferable in clinical decision support systems** where stakeholder trust and explainability are essential.\n",
    "- Random forest remains valuable for **nonlinear signal detection** and **feature ranking**, and could shine with further tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c201ad",
   "metadata": {},
   "source": [
    "## Saving Trained Models for Reuse\n",
    "\n",
    "To support reproducibility and deployment, we serialize both trained models using `joblib`. Saving models allows us to reuse them for inference, diagnostics, or integration into future pipelines without retraining.\n",
    "\n",
    "We will also save the `StandardScaler` used for logistic regression, so future inputs can be transformed consistently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ae43c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import os\n",
    "\n",
    "# Create model directory if it doesn't exist\n",
    "os.makedirs(\"../models\", exist_ok=True)\n",
    "\n",
    "# Save logistic regression model and scaler\n",
    "joblib.dump(logreg, \"../models/logistic_regression_model.joblib\")\n",
    "joblib.dump(scaler, \"../models/logreg_scaler.joblib\")\n",
    "\n",
    "# Save random forest model\n",
    "joblib.dump(rf, \"../models/random_forest_model.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f856c642",
   "metadata": {},
   "source": [
    "## Models Saved Successfully\n",
    "\n",
    "- `logistic_regression_model.joblib`: Serialized logistic regression classifier\n",
    "- `logreg_scaler.joblib`: Fitted `StandardScaler` for preprocessing numerical features before logistic prediction\n",
    "- `random_forest_model.joblib`: Trained Random Forest classifier\n",
    "\n",
    "These models are now ready for:\n",
    "- Direct reuse in production or evaluation scripts\n",
    "- Integration into web apps or dashboards\n",
    "- Deployment to inference pipelines with matching preprocessing\n",
    "\n",
    "Saving both model and scaler ensures **reproducible predictions** across environments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a43fb5",
   "metadata": {},
   "source": [
    "## PAIR Guidebook – Explainability + Trust: Key Takeaways\n",
    "\n",
    "1. **People don’t just want to know what the model predicts — they want to know why.**  \n",
    "   Stakeholders, especially in clinical settings, are more likely to trust and use models when they can trace outcomes to meaningful features.\n",
    "\n",
    "2. **Simple models (like Logistic Regression) offer built-in transparency.**  \n",
    "   Coefficients show direct relationships between features and outcomes, supporting interpretability even if performance is slightly lower.\n",
    "\n",
    "3. **Complex models (like Random Forests) must offer surrogate explanations.**  \n",
    "   Feature importances and tools like SHAP or LIME help surface which inputs influenced a decision, promoting trust without revealing internals.\n",
    "\n",
    "These principles reinforce our decision to:\n",
    "- Present and interpret both coefficient-based and tree-based feature relevance\n",
    "- Use visualizations and plain-English markdown to support stakeholder understanding"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hcmle-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
