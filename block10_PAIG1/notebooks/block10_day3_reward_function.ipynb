{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54383288",
   "metadata": {},
   "source": [
    "## Reflection: User-Centered Success vs Model-Centered Accuracy\n",
    "\n",
    "- **Model accuracy** (e.g., % correct answers) is necessary but not sufficient.\n",
    "- **User-centered success** might include:\n",
    "  - Confidence improvement\n",
    "  - Time saved per task\n",
    "  - Fewer escalations to human tutor\n",
    "  - User trust in AI suggestions\n",
    "  - Reduced dropout or frustration\n",
    "\n",
    "In this product, success is when [insert user outcome here, e.g., \"students feel supported and solve problems faster\"] — not merely when the model predicts the correct formula."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2932dc1",
   "metadata": {},
   "source": [
    "## Map Human-Centered Success Metrics\n",
    "| Category   | Example Metric                                      | Type         |\n",
    "|------------|-----------------------------------------------------|--------------|\n",
    "| Outcome    | Avg. time to solve a problem                        | Quantitative |\n",
    "| Behavior   | % of questions answered without escalation          | Quantitative |\n",
    "| Perception | Trust rating (1–5 scale)                            | Qualitative  |\n",
    "| Engagement | # of problems attempted per session                 | Quantitative |\n",
    "| Recovery   | % of cases with helpful fallback after wrong output | Qualitative  |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1dd17a",
   "metadata": {},
   "source": [
    "## Reward Function Summary for Tangent (AI Calculus Assistant)\n",
    "\n",
    "### 1. Objective\n",
    "To guide model behavior in a way that **maximizes helpfulness, builds user trust**, and **avoids confidently wrong answers**, while supporting students through flexible, low-friction tutoring.\n",
    "\n",
    "### 2. Rewarded Behaviors\n",
    "\n",
    "| Behavior                                                 | Reward | Rationale                                             |\n",
    "|----------------------------------------------------------|--------|--------------------------------------------------------|\n",
    "| Problem solved correctly without help                    | +1.0   | Encourages accurate, self-sufficient answers           |\n",
    "| AI admits uncertainty and offers to escalate to tutor    | +0.5   | Rewards honest boundaries and user-centered escalation |\n",
    "| Student confirms they feel more confident after session  | +0.5   | Reinforces the emotional/educational goal              |\n",
    "| AI provides partially correct guidance leading to solution | +0.25  | Supports helpfulness over perfection                   |\n",
    "| Clear explanation with formula + visual aid              | +0.25  | Encourages multimodal communication and clarity        |\n",
    "\n",
    "### 3. Penalized Behaviors\n",
    "\n",
    "| Behavior                                                       | Penalty | Rationale                                              |\n",
    "|----------------------------------------------------------------|---------|---------------------------------------------------------|\n",
    "| Confidently wrong answer                                       | –1.0    | Breaks trust and causes user confusion or harm          |\n",
    "| Repeatedly offers incorrect answers without escalation         | –0.75   | Fails to adapt to edge cases                            |\n",
    "| Long-winded or vague responses                                 | –0.25   | Increases cognitive load, wastes user time              |\n",
    "| Using overly technical language with novice users              | –0.25   | Reduces accessibility and perceived usefulness          |\n",
    "\n",
    "### 4. Reinforcement Signals\n",
    "\n",
    "| Signal Source                      | What It Measures                     | Frequency      |\n",
    "|-----------------------------------|--------------------------------------|----------------|\n",
    "| User feedback (thumbs/trust score)| Satisfaction, trust                  | Per session    |\n",
    "| Task resolution (based on logs)   | Accuracy + completion path           | Per problem    |\n",
    "| Session metadata                  | Time to resolution, escalation rate  | Per session    |\n",
    "| Drop-off rate                     | Engagement and failure handling      | Aggregated     |\n",
    "\n",
    "### 5. Edge Case & Pitfall Handling\n",
    "\n",
    "| Pitfall                                      | Risk                                | Mitigation                                      |\n",
    "|---------------------------------------------|-------------------------------------|-------------------------------------------------|\n",
    "| Over-optimizing for speed                   | Rushed, unclear answers             | Add reward for clarity, penalize vagueness      |\n",
    "| Avoiding escalation to maximize score       | User frustration, unresolved issues | Reward **smart escalation**, not \"no help\"      |\n",
    "| Manipulating trust feedback                 | Artificial trust inflation          | Weight feedback with context and session length |\n",
    "\n",
    "### 6. Final Reward Function (Narrative Form)\n",
    "\n",
    "*Tangent's reward function favors helpful, trustworthy, and efficient interactions. The system is rewarded for solving problems correctly, offering clear guidance, and knowing when to escalate. It is penalized for confidently wrong answers, vague explanations, and failing to adapt to the user’s level. The ultimate goal is not just correctness, but building a tutoring experience that students return to and feel supported by.*\n",
    "\n",
    "### Why This Is Human-Centered\n",
    "\n",
    "- Rewards **confidence-building**, not just correctness  \n",
    "- Reflects **emotional outcomes** like trust  \n",
    "- Encourages **honesty in uncertainty**  \n",
    "- Considers **accessibility and user clarity** alongside technical performance  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6e4174",
   "metadata": {},
   "source": [
    "## Summary\n",
    "- Defined success using qualitative and quantitative human-centered metrics\n",
    "- Designed reward function aligned with trust, resolution, and helpful behavior\n",
    "- Reframed \"model success\" as \"user success\""
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
